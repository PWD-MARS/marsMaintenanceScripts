---
title: "Worker Script: Update GreenIT Tables"
author: "Monica Gucciardi"
date: "`r lubridate::now()`"
output: html_document

---

```{r Section 0.1 Setup and DB connections, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

#database packages
library(pool)
library(odbc)
library(RPostgres)

#data manipulation packages
library(pwdgsi)
library(tidyverse)
library(tidyr)
library(knitr)

#hashing packages
library(digest)

#db connections 
greenit <- dbConnect(odbc(),
                     Driver = "ODBC Driver 17 for SQL Server",  
                     Server = "PWDSQLPLENVPROD", 
                     Database = "GreenIT", 
                     uid = Sys.getenv("greenit_uid"), 
                     pwd = Sys.getenv("greenit_pwd"))

mars_data <- dbConnect(
  drv = RPostgres::Postgres(),
  host = "PWDMARSDBS1",
  port = 5434,
  dbname = "mars_prod",
  user= Sys.getenv("admin_uid"),
  password = Sys.getenv("admin_pwd"),
  timezone = NULL)

errorCodes <- data.frame(code = 0:5,
  message = c("Execution successful.",
              "Could not connect to Postgres and/or GreenIT. Is the database down?",
              "Failed to download a BDV from GreenIT",
              NA, #Write error from TryCatch will be used
              NA, #Write error from TryCatch will be used
              NA #Write error from TryCatch will be used
               ), stringsAsFactors=FALSE)

log_code <- digest(now()) #Unique ID for the log batches

  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = 1,
                           exit_code = NA,
                           note = "Checking DB connections")
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)


kill = FALSE
success = FALSE
errorCode = 0


#################################
####Error check - Did we connect?
#################################
if(any(!odbc::dbIsValid(mars_data), !odbc::dbIsValid(greenit)))
{
  kill = TRUE
  errorCode = 1
}
```

```{r Break Point 1 - Bad Connection, echo = FALSE, eval = kill}

  knitr::asis_output("# Script Results: Error\n")
  knitr::asis_output(paste("## Error Code:", errorCode, "\n"))
  knitr::asis_output(paste("## Error Message: ", errorCodes$message[errorCode+1]))
  
  ###Log: End
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = NA,
                           exit_code = errorCode,
                           note = errorCodes$message[errorCode+1])
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)
  
  knitr::knit_exit()

```
#### The goal of this script is to succesfully read smp, system and project data from the `GreenIT` database and write a copy of new and updated records to`mars_data`.

```{r Section 1: Query GreenIT, echo = FALSE}

  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = 2,
                           exit_code = NA,
                           note = "Querying GreenIT")
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)
  
  #The following query sequence is our latest workarounf for the "Invalid Descriptor Index bug when querying SQL Server via ODBC.
  #The process was adapted from here: https://github.com/r-dbi/odbc/issues/309#issuecomment-617846668
  
  #The nvarchar data types with length 0 (aka arbitrary length) choke a direct query because of a bug in SQL Server's ODBC implementation
  #It has something to do with columns with a large maximum length needing to come last in the query order
  #By attempting to query other columns after querying them, something breaks
  
  #By using dplyr as an intermediary in the process, this problem can be avoided
  #We can query the normal stuff without the long stuff, then the long stuff separately
  
  #This works with SQL Server ODBC driver 17, odbc package 1.2.2, and the data types in the GreenIT Best Data Views as of November 2024
  
  #Raw table query
  smp_query <- "select ProjectID as project_id, SMP_DataPhase as smp_dataphase, WorkNumber as worknumber, Status as cipit_status, StatusCategory as cipit_statuscategory, SystemNumber as system_id, SMPNumber as smp_id, SMP_SMPType as smp_smptype, SMP_FootPrint as smp_footprint_ft2, SMP_SMPTrees as smp_smptrees, SMP_PerviousArea as smp_perviousarea_ft2, SMP_VegetatedArea as smp_vegetatedarea_ft2, SMP_StorageDepth as smp_storagedepth_ft, SMP_PondingDepth as smp_pondingdepth_in, SMP_StorageType as smp_storagetype, SMP_Pretreatment as smp_pretreatment, SMP_NotBuiltRetired as smp_notbuiltretired, SMP_NotBuiltRetiredReason as smp_notbuiltretiredreason from vw_GreenIT_SMPBestData"
  
  #Fetch the column names and data types/lengths, but no data (doesn't choke)
  long_cols <- odbc::odbcConnectionColumns(greenit, "vw_GreenIT_SMPBestData") %>%
    dplyr::select(name, data_type, column_size) %>% 
    dplyr::filter(data_type == -9,
                  column_size == 0) %>%
    dplyr::arrange(column_size) %>%
    dplyr::pull(name)

  smpbestdata <- dplyr::tbl(greenit, dplyr::sql(smp_query)) %>%
    dplyr::select(-tidyselect::all_of(tolower(long_cols)), #Delete the long columns from the query
                  tidyselect::everything(),
                  tidyselect::all_of(tolower(long_cols))) %>% #Add them back at the end
    as.data.frame #Make it a regular data frame instead of the dbplyr lazy table
  
  
  
  #We need to repeat this process for the other two BDVs 
  
  
  
  #Raw table query
  system_query <- "select Sys_DataPhase as sys_dataphase, WorkNumber as worknumber, Status as cipit_status, StatusCategory as cipit_statuscategory, ProjectID as project_id, SystemNumber as system_id, Sys_PrimaryProgram as sys_primaryprogram, Sys_SecondaryPrograms as sys_secondaryprograms, Sys_SewerType as sys_sewertype, Sys_OverFlowType as sys_overflowtype, Sys_SysFunction as sys_sysfunction, Sys_ModelInputCategory as sys_modelinputcategory, Sys_ImpervDA as sys_impervda_ft2, Sys_SurfaceDCIA as sys_surfacedcia_ft2, Sys_SubsurfaceDCIA as sys_subsurfacedcia_ft2, Sys_PerviousDA as sys_perviousda_ft2, Sys_TotalDA as sys_totalda_ft2, Sys_DisconnectedArea as sys_disconnectedarea_ft2, Sys_StorageVolume as sys_storagevolume_ft3, Sys_TotalSysVolume as sys_totalsysvolume_ft3, Sys_SoilStorageVolume as sys_soilstoragevolume_ft3, Sys_PondedStorageVolume as sys_pondedstoragevolume_ft3, Sys_VolumeBelowOrifice as sys_volumebeloworifice_ft3, Sys_CreditedGA as sys_creditedga, Sys_RawGA as sys_rawga, Sys_InfilDepth as sys_infildepth_ft, Sys_SlowReleaseHead as sys_slowreleasehead_ft, Sys_StorageFootPrint as sys_storagefootprint_ft2, Sys_InfilFootPrint as sys_infilfootprint_ft2, Sys_PondingSurfaceArea as sys_pondingsurfacearea_ft2, Sys_OrificeDia as sys_orificedia_in, Sys_Underdrain as sys_underdrain, Sys_PeakReleaseRate as sys_peakreleaserate_cfs, Sys_RawStormSizeManaged as sys_rawstormsizemanaged_in, Sys_ModeledStormSizeManaged as sys_modeledstormsizemanaged_in, Sys_CreditedStormSizeManaged as sys_creditedstormsizemanaged_in, Sys_LRimpervDA as sys_lrimpervda_ft2, Sys_LRtotalDA as sys_lrtotalda_ft2, Sys_LRSurfaceDCIA as sys_lrsurfacedcia_ft2, Sys_LRSubsurfaceDCIA as sys_lrsubsurfacedcia_ft2, Sys_NotBuiltRetired as sys_notbuiltretired, Sys_NotBuiltRetiredReason as sys_notbuiltretiredreason, Infil_Dsg_TestDate as infil_dsg_testdate, Infil_Dsg_TestType as infil_dsg_testtype, Infil_Dsg_BoringDepth as infil_dsg_boringdepth_ft, Infil_Dsg_DepthtoGW as infil_dsg_depthtogw_ft, Infil_Dsg_DepthtoBedrock as infil_dsg_depthtobedrock_ft, Infil_Dsg_Rate as infil_dsg_rate_inhr, Infil_Constr_TestDate as infil_constr_testdate, Infil_Constr_TestType as infil_constr_testtype, Infil_Constr_Rate as infil_constr_rate_inhr from vw_greenit_systembestdata"
  
  #Fetch the column names and data types/lengths, but no data (doesn't choke)
  long_cols <- odbc::odbcConnectionColumns(greenit, "vw_greenit_systembestdata") %>%
    dplyr::select(name, data_type, column_size) %>% 
    dplyr::filter(data_type == -9,
                  name != "GreenContact", #We don't pull these (we should, to fix soon)
                  column_size == 0) %>%
    dplyr::arrange(column_size) %>%
    dplyr::pull(name)
  
  systembestdata <- dplyr::tbl(greenit, dplyr::sql(system_query)) %>%
    dplyr::select(-tidyselect::all_of(tolower(long_cols)), #Delete the long columns from the query
                  tidyselect::everything(),
                  tidyselect::all_of(tolower(long_cols))) %>% #Add them back at the end
    as.data.frame #Make it a regular data frame instead of the fancy dbplyr lazy table
  

  project_query <- "select ProjectID as project_id, WorkNumber as worknumber, Proj_ProjectName as proj_projectname, Status as cipit_status, StatusCategory as cipit_statuscategory, Proj_PrimaryProgram as proj_primaryprogram, ProjSysSum_PrimaryProgram as projsyssum_primaryprogram, Proj_PilotFactor as proj_pilotfactor, Proj_X as proj_x, Proj_Y as proj_y, Proj_DataPhase as proj_dataphase, Proj_SewerType as proj_sewertype, ProjSysSum_SewerTypes as projsyssum_sewertypes, Proj_BestGA as proj_bestga, Proj_BestDA as proj_bestda_ft2, Proj_EstimatedGA as proj_estimatedga, Proj_EstimatedDA as proj_estimatedda_ft2, ProjSysSum_CreditedGA as projsyssum_creditedga, ProjSysSum_RawGA as projsyssum_rawga, ProjSysSum_ImpervDA as projsyssum_impervda_ft2, ProjSysSum_StorageVolume as projsyssum_storagevolume_ft3, ProjSMPSum_PerviousArea as projsmpsum_perviousarea_ft2, Proj_NonSMPTrees as proj_nonsmptrees, ProjSMPSum_SMPTrees as projsmpsum_smptrees, ProjSMPSum_Basins as projsmpsum_basins, ProjSMPSum_BlueRoofs as projsmpsum_blueroofs, ProjSMPSum_Bumpouts as projsmpsum_bumpouts, ProjSMPSum_Cisterns as projsmpsum_cisterns, ProjSMPSum_Depaving as projsmpsum_depaving, ProjSMPSum_DrainageWells as projsmpsum_drainagewells, ProjSMPSum_GreenGutters as projsmpsum_greengutters, ProjSMPSum_GreenRoofs as projsmpsum_greenroofs, ProjSMPSum_InfilTrenches as projsmpsum_infiltrenches, ProjSMPSum_PerviousPaving as projsmpsum_perviouspaving, ProjSMPSum_Planters as projsmpsum_planters, ProjSMPSum_RainGardens as projsmpsum_raingardens, ProjSMPSum_StormwaterTrees as projsmpsum_stormwatertrees, ProjSMPSum_Swales as projsmpsum_swales, ProjSMPSum_TreeTrenches as projsmpsum_treetrenches, ProjSMPSum_Wetlands as projsmpsum_wetlands from vw_greenit_projectbestdata"

  long_cols <- odbc::odbcConnectionColumns(greenit, "vw_greenit_projectbestdata") %>%
    dplyr::select(name, data_type, column_size) %>% 
    dplyr::filter(data_type == -9,
                  name != "ProjSysSum_SecondaryProgram", #We don't pull these (we should, to fix soon)
                  column_size == 0) %>%
    dplyr::arrange(column_size) %>%
    dplyr::pull(name)
  
  projectbestdata <- dplyr::tbl(greenit, dplyr::sql(project_query)) %>%
    dplyr::select(-tidyselect::all_of(tolower(long_cols)), #Delete the long columns from the query
                  tidyselect::everything(),
                  tidyselect::all_of(tolower(long_cols))) %>% #Add them back at the end
    as.data.frame #Make it a regular data frame instead of the fancy dbplyr lazy table

###Error Check: Did we fail to download any tables from GreenIT?
if(any(!exists("smpbestdata"), !exists("systembestdata"), !exists("projectbestdata"))){
  kill = TRUE
  errorCode = 2
}

```

```{r Break Point 2 - Empty read, echo = FALSE, eval = kill}

  knitr::asis_output("# Script Results: Error\n")
  knitr::asis_output(paste("## Error Code:", errorCode, "\n"))
  knitr::asis_output(paste("## Error Message: ", errorCodes$message[errorCode+1]))
  
  ###Log: End
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = NA,
                           exit_code = errorCode,
                           note = errorCodes$message[errorCode+1])
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)
  
  knitr::knit_exit()

```

```{r Filter for new projects, echo = FALSE, include = FALSE}

  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = 3,
                           exit_code = NA,
                           note = "Hashing GreenIT Data")
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)

#Hash what we got from GreenIT
smp_hash <- smpbestdata %>%
    unite("temp", sep = " ", remove = FALSE) %>%
    rowwise() %>%
    mutate(hash_md5 = digest(temp, algo = 'md5')) %>%
    select(-temp)

system_hash <- systembestdata %>% 
    unite("temp", sep = " ", remove = FALSE) %>%
    rowwise() %>%
    mutate(hash_md5 = digest(temp, algo = 'md5')) %>%
    select(-temp)
  
project_hash <- projectbestdata %>% 
    unite("temp", sep = " ", remove = FALSE) %>%
    rowwise() %>%
    mutate(hash_md5 = digest(temp, algo = 'md5')) %>%
    select(-temp)

#Query Mars database
smp_md <- dbGetQuery(mars_data, "select * from external.tbl_smpbdv")
system_md <- dbGetQuery(mars_data, "select * from external.tbl_systembdv")
project_md <- dbGetQuery(mars_data, "select * from external.tbl_projectbdv")

# Compare and find new SMPs, system, and projects -----
new_smps <- smp_hash %>% anti_join(smp_md, by = c("smp_id"))
new_systems <- system_hash %>%  anti_join(system_md, by = c("system_id"))
new_projects <- project_hash %>% anti_join(project_md, by = c("project_id"))

newAssets <- FALSE

#If there are any new records to append, fire the subsequent blocks.
#If not, skip to the update blocks.
if(any(nrow(new_smps) > 0, nrow(new_systems) > 0, nrow(new_projects) > 0)){
  newAssets <- TRUE
}

```

```{r Section We Are As One - external.tbl_smpbdv, echo = FALSE, eval = all(!kill, newAssets, nrow(new_smps) > 0)}
###New SMP Polygons
knitr::asis_output(paste("### New SMPs to add to `external.tbl_smpbdv`: ",   nrow(new_smps)))
kable(head(new_smps))
```

```{r Section We Are As One - external.tbl_systembdv, echo = FALSE, eval = all(!kill, newAssets, nrow(new_systems) > 0)}
knitr::asis_output(paste("### New systems to add to `external.tbl_systembdv`: ",   nrow(new_systems)))
kable(head(new_systems))
```

```{r Section We Are As One - external.tbl_projectbdv, echo = FALSE, eval = all(!kill, newAssets, nrow(new_projects) > 0)}
knitr::asis_output(paste("### New projects to add to `external.tbl_projectbdv`: ",   nrow(new_projects)))
kable(head(new_projects))
```

```{r Section We Are As One - Write Everything, echo = FALSE, eval = all(!kill, newAssets)}
  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = 4,
                           exit_code = NA,
                           note = "Writing New Data")
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)

#Write new assets
if(newAssets){
  
  tryCatch(
    expr = {
      dbWriteTable(mars_data, RPostgres::Id(schema = "external", table = "tbl_smpbdv"), new_smps, append = TRUE)
      dbWriteTable(mars_data, RPostgres::Id(schema = "external", table = "tbl_systembdv"), new_systems, append = TRUE)
      dbWriteTable(mars_data, RPostgres::Id(schema = "external", table = "tbl_projectbdv"), new_projects, append = TRUE)
      # success = TRUE
    },
    error = function(e){
      kill <<- TRUE
      errorCode <<- 3
      errorCodes$message[errorCode+1] <<- e$message #Error object is a list
    }
  )
}

if(!kill){
  new_records <- sum(nrow(new_smps), nrow(new_systems), nrow(new_projects))
  logMessage <- data.frame(date = as.Date(today()),
                     records = new_records,
                     type = "Records",
                     hash = log_code)

  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_writes_greenit"), logMessage, append = TRUE, row.names=FALSE)
}

```

```{r Break Point 3 - Bad Write, echo = FALSE, eval = kill}

  knitr::asis_output("# Script Results: Error\n")
  knitr::asis_output(paste("## Error Code:", errorCode, "\n"))
  knitr::asis_output(paste("## Error Message: ", errorCodes$message[errorCode+1]))
  
  ###Log: End
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = NA,
                           exit_code = errorCode,
                           note = errorCodes$message[errorCode+1])
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)
  
  knitr::knit_exit()

```

```{r Section 3: Rerun Query and Update Data in Postgres, echo = FALSE}

#3.1 Redownload UIDs and IDs to find UIDs for newly-added records
smp_uids <- dbGetQuery(mars_data, "select smpbdv_uid, smp_id from external.tbl_smpbdv")
system_uids <- dbGetQuery(mars_data, "select systembdv_uid, system_id from external.tbl_systembdv")
project_uids <- dbGetQuery(mars_data, "select projectbdv_uid, project_id from external.tbl_projectbdv")


#3.2 Update changed records. To do this, we will need to key off of record UIDs, which the GreenIT tables don't have.
# So first we join the GreenIT table to this trimmed set of records that we downloaded in 3.1
# Then we anti-join based on the composite key of SMP ID + Hash. If the hash is different, then we know the GreenIT row has changed.

#Notably, for this kind of update to work, the record UID needs to be the last column in the DF, because the DF colnames are substituted for the ?s in the dbSendQuery statements.
update_smps <- smp_hash %>% 
  left_join(smp_uids, by = "smp_id") %>% 
  anti_join(smp_md, by = c("smp_id", "hash_md5"))
  
update_systems <- system_hash %>%
  left_join(system_uids, by = "system_id") %>%
  anti_join(system_md, by = c("system_id", "hash_md5")) 
  
update_projects <- project_hash %>%
  left_join(project_uids, by = "project_id") %>% 
  anti_join(project_md, by = c("project_id", "hash_md5")) %>%
  mutate(proj_projectname = iconv(proj_projectname, from = "latin1", to = "UTF8", sub = " "))

newUpdates <- FALSE

#If there are any new records to append, fire the subsequent blocks.
#If not, skip to the update blocks.
if(any(nrow(update_smps) > 0, nrow(update_systems) > 0, nrow(update_projects) > 0)){
  newUpdates <- TRUE
}

```

```{r Section We Are As One - Updates to external.tbl_gswibasin, echo = FALSE, include = TRUE, eval = all(!kill, newUpdates, nrow(update_smps) > 0)}
knitr::asis_output(paste("### SMPs to update in `external.tbl_smpbdv`: ",   nrow(update_smps)))
kable(head(update_smps))
```

```{r Section We Are As One - Updates to external.tbl_gswiblueroof, echo = FALSE, include = TRUE, eval = all(!kill, newUpdates, nrow(update_systems) > 0)}
knitr::asis_output(paste("### Systems to update in `external.tbl_systembdv`: ",   nrow(update_systems)))
kable(head(update_systems))
```

```{r Section We Are As One - Updates to external.tbl_gswibumpout, echo = FALSE, include = TRUE, eval = all(!kill, newUpdates, nrow(update_projects) > 0)}
knitr::asis_output(paste("### Projects to update in `external.tbl_projectbdv`: ",   nrow(update_projects)))
kable(head(update_projects))
```


```{r Section We Are As One - Update Everything, echo = FALSE, eval = all(!kill, newUpdates)}
  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = 5,
                           exit_code = NA,
                           note = "Updating GreenIT Data")
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)

#Write new assets
if(newUpdates){
  
  tryCatch(
    expr = {
        #Update old assets
        if(nrow(update_smps) > 0){
          update_smps <- as.data.frame(update_smps) #Required by RPostgres for parameterized queries. Annoying!
          colnames(update_smps) <- NULL #Tibbles can't have null colnames. Super annoying!!
            #https://stackoverflow.com/questions/56728611/how-to-use-parameterized-query-using-r-and-rpostgres-so-as-to-accept-values-cont
          update_smpquery <- dbSendQuery(mars_data, 'update external.tbl_smpbdv set project_id=$1, smp_dataphase=$2, worknumber=$3, cipit_status=$4, cipit_statuscategory=$5, system_id=$6, smp_id=$7, smp_smptype=$8, smp_footprint_ft2=$9, smp_smptrees=$10, smp_perviousarea_ft2=$11, smp_vegetatedarea_ft2=$12, smp_storagedepth_ft=$13, smp_pondingdepth_in=$14, smp_notbuiltretired=$15, smp_notbuiltretiredreason=$16, smp_storagetype=$17, smp_pretreatment=$18, hash_md5=$19 WHERE smpbdv_uid=$20')
            dbBind(update_smpquery, update_smps)
            dbClearResult(update_smpquery)
        }

        if(nrow(update_systems) > 0){
          update_systems <- as.data.frame(update_systems) #Required by RPostgres for parameterized queries. Annoying!
          colnames(update_systems) <- NULL #Tibbles can't have null colnames. Super annoying!!
            update_systemquery <- dbSendQuery(mars_data, 'update external.tbl_systembdv set sys_dataphase=$1, worknumber=$2, cipit_status=$3, cipit_statuscategory=$4, project_id=$5, system_id=$6, sys_primaryprogram=$7, sys_sewertype=$8, sys_overflowtype=$9, sys_sysfunction=$10, sys_modelinputcategory=$11, sys_impervda_ft2=$12, sys_surfacedcia_ft2=$13, sys_subsurfacedcia_ft2=$14, sys_perviousda_ft2=$15, sys_totalda_ft2=$16, sys_disconnectedarea_ft2=$17, sys_storagevolume_ft3=$18, sys_totalsysvolume_ft3=$19, sys_soilstoragevolume_ft3=$20, sys_pondedstoragevolume_ft3=$21, sys_volumebeloworifice_ft3=$22, sys_creditedga=$23, sys_rawga=$24, sys_infildepth_ft=$25, sys_slowreleasehead_ft=$26, sys_storagefootprint_ft2=$27, sys_infilfootprint_ft2=$28, sys_pondingsurfacearea_ft2=$29, sys_orificedia_in=$30, sys_underdrain=$31, sys_peakreleaserate_cfs=$32, sys_rawstormsizemanaged_in=$33, sys_modeledstormsizemanaged_in=$34, sys_creditedstormsizemanaged_in=$35, sys_lrimpervda_ft2=$36, sys_lrtotalda_ft2=$37, sys_lrsurfacedcia_ft2=$38, sys_lrsubsurfacedcia_ft2=$39, sys_notbuiltretired=$40, sys_notbuiltretiredreason=$41, infil_dsg_testdate=$42, infil_dsg_testtype=$43, infil_dsg_boringdepth_ft=$44, infil_dsg_depthtogw_ft=$45, infil_dsg_depthtobedrock_ft=$46, infil_dsg_rate_inhr=$47, infil_constr_testdate=$48, infil_constr_testtype=$49, infil_constr_rate_inhr=$50, sys_secondaryprograms=$51, hash_md5=$52 WHERE systembdv_uid =$53')
            dbBind(update_systemquery, update_systems)
            dbClearResult(update_systemquery)
        }

        if(nrow(update_projects) > 0){
          update_projects <- as.data.frame(update_projects) #Required by RPostgres for parameterized queries. Annoying!
          colnames(update_projects) <- NULL #Tibbles can't have null colnames. Super annoying!!
          
            update_projectquery <- dbSendQuery(mars_data, 'update external.tbl_projectbdv set project_id=$1, worknumber=$2, proj_projectname=$3, cipit_status=$4, cipit_statuscategory=$5, proj_pilotfactor=$6, proj_x=$7, proj_y=$8, proj_dataphase=$9, proj_bestga=$10, proj_bestda_ft2=$11, proj_estimatedga=$12, proj_estimatedda_ft2=$13, projsyssum_creditedga=$14, projsyssum_rawga=$15, projsyssum_impervda_ft2=$16, projsyssum_storagevolume_ft3=$17, projsmpsum_perviousarea_ft2=$18, proj_nonsmptrees=$19, projsmpsum_smptrees=$20, projsmpsum_basins=$21, projsmpsum_blueroofs=$22, projsmpsum_bumpouts=$23, projsmpsum_cisterns=$24, projsmpsum_depaving=$25, projsmpsum_drainagewells=$26, projsmpsum_greengutters=$27, projsmpsum_greenroofs=$28, projsmpsum_infiltrenches=$29, projsmpsum_perviouspaving=$30, projsmpsum_planters=$31, projsmpsum_raingardens=$32, projsmpsum_stormwatertrees=$33, projsmpsum_swales=$34, projsmpsum_treetrenches=$35, projsmpsum_wetlands=$36, proj_primaryprogram=$37, projsyssum_primaryprogram=$38, proj_sewertype=$39, projsyssum_sewertypes=$40, hash_md5=$41 WHERE projectbdv_uid=$42')
            dbBind(update_projectquery, update_projects)
            dbClearResult(update_projectquery)
        }
    },
    error = function(e){
      kill <<- TRUE
      errorCode <<- 4
      errorCodes$message[errorCode+1] <<- e$message #Error object is a list
    }
  )
}
  
if(!kill){
  updated_records <- nrow(update_smps) + nrow(update_systems) + nrow(update_projects)
  logMessage <- data.frame(date = as.Date(today()),
                     records = updated_records,
                     type = "Updates",
                     hash = log_code)

  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_writes_greenit"), logMessage, append = TRUE, row.names=FALSE)
}
    
```

```{r Break Point 4 - Bad Update, echo = FALSE, eval = kill}

  knitr::asis_output("# Script Results: Error\n")
  knitr::asis_output(paste("## Error Code:", errorCode, "\n"))
  knitr::asis_output(paste("## Error Message: ", errorCodes$message[errorCode+1]))
  
  ###Log: End
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = NA,
                           exit_code = errorCode,
                           note = errorCodes$message[errorCode+1])
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)
  
  knitr::knit_exit()

```

# Script Results: `r ifelse(kill, "FAILURE", "SUCCESS")`
## Exit Code: `r errorCode`
## Exit Message: `r errorCodes$message[errorCode+1]`

```{r Section 4: Clean Up Connections and Render This HTML Document, include = FALSE}
  ###Log: End
  logMessage <- data.frame(date = as.Date(today()), hash = log_code,
                           milestone = NA,
                           exit_code = errorCode,
                           note = errorCodes$message[errorCode+1])
  
  dbWriteTable(mars_data, RPostgres::Id(schema = "log", table = "tbl_script_greenit"), logMessage, append = TRUE, row.names=FALSE)

dbDisconnect(greenit)
```

