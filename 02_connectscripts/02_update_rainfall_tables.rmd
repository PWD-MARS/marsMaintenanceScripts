---
title: "Script Test"
output: html_document
date: "`r Sys.Date()`"
params:
  database: "mars_testdeploy"
---
```{r setup, include=FALSE}
#Database Stuff
library(pool)
library(RPostgres)
library(tidyverse)
library(lubridate)
library(pwdgsi)
library(padr)

#Other stuff
library(knitr)
library(digest)
options(stringsAsFactors=FALSE)


errorCodes <- data.frame(code = 0:6,
  message = c("Execution successful.",
              "Could not connect to MARS and/or CentralDB. Are they down?",
              NA, #Write error from TryCatch will be used,
              NA, #Write error from TryCatch will be used,
              NA, #Write error from TryCatch will be used
              NA, #Write error from TryCatch will be used
              NA)
            , stringsAsFactors=FALSE)

kill = FALSE
errorCode = 0

logCode <- digest(now()) #Unique ID for the log batches

#Are we running locally or on RStudio Connect?
  #We will check if a filepath that only exists on Connect exists.
  #We will use this to determine the prefix for the filepaths to the H&H radar files
locationCheck <- list.files("/media/mounts/RadarRainfall/Data")

if(length(locationCheck) == 0){ 
  #We are running locally (ie debugging/developing)
  radarFolder <- "//pwdoows/oows/Modeling/Data/H&H Databases/RadarRainfall/Data"
  unzipFolder <- "//pwdoows/oows/Watershed Sciences/GSI Monitoring/12 GSI Data Management and Analysis/01 Admin/03 MARS Maintenance Scripts/unzip"
} else{
  #We are running on Connect
  radarFolder <- "/media/mounts/RadarRainfall/Data"
  unzipFolder <- "/media/mounts/gsi-monitoring/12 GSI Data Management and Analysis/01 Admin/03 MARS Maintenance Scripts/unzip"
}


```

```{r connections, include=FALSE}

#Connect to the MARS database
marsDBCon <- tryCatch({
  dbPool(
    drv = RPostgres::Postgres(),
    host = "PWDMARSDBS1",
    port = 5434,
    dbname = "sandbox_dtime",
    user= Sys.getenv("admin_uid"),
    password = Sys.getenv("admin_pwd"),
    timezone = NULL)},
  error = function(e){e})

centraldb <- tryCatch({
  dbPool(
    drv = RPostgres::Postgres(),
    host = "192.168.131.120",
    port = 5432,
    dbname = "CentralDB",
    user= Sys.getenv("central_uid"),
    password = Sys.getenv("central_pwd"),
    timezone = NULL)},
  error = function(e){e})

  #################################
  ####Error check - Did we connect?
  #################################
  if(any(typeof(marsDBCon) == "list", typeof(centraldb) == "list"))
  {
    kill = TRUE
    errorCode = 1
  }
  
  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = logCode,
                           milestone = 1,
                           exit_code = NA,
                           note = "Testing DB connections")
  
  if(!kill){
    dbWriteTable(marsDBCon, RPostgres::Id(schema = "log", table = "tbl_script_rainfall"), logMessage, append = TRUE, row.names=FALSE)
    
    #Debug mode, truncation of relevant tables to test i/o
    #Remove this before shipping, for the love of god
    dbExecute(marsDBCon, "truncate table data.tbl_gage_rain restart identity;")
    dbExecute(marsDBCon, "truncate table data.tbl_gage_event restart identity;")
    dbExecute(marsDBCon, "truncate table admin.tbl_radar_rawfile;")
    dbExecute(marsDBCon, "truncate table data.tbl_radar_rain restart identity;")
    dbExecute(marsDBCon, "truncate table data.tbl_radar_event restart identity;")

  }

```

```{r Break Point 1 - Connection Failure, echo = FALSE, include = TRUE, eval = kill}

  knitr::asis_output("# Script Results: Error\n")
  knitr::asis_output(paste("## Error Code:", errorCode, "\n"))
  knitr::asis_output(paste("## Error Message: ", errorCodes$message[errorCode+1]))

  # ###Log: End
  # logMessage <- data.frame(date = as.Date(today()), hash = logCode,
  #                          milestone = NA,
  #                          exit_code = errorCode,
  #                          note = errorCodes$message[errorCode+1])
  # 
  # dbWriteTable(marsDBCon, RPostgres::Id(schema = "log", table = "tbl_script_rainfall"), logMessage, append = TRUE, row.names=FALSE)
  
  knitr::knit_exit()

```

```{r Gather Rain Gage Data from MARS, echo=FALSE, include = TRUE, eval = !kill}
  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = logCode,
                           milestone = 2,
                           exit_code = NA,
                           note = "Gathering Gage Data")
  
  dbWriteTable(marsDBCon, RPostgres::Id(schema = "log", table = "tbl_script_rainfall"), logMessage, append = TRUE, row.names=FALSE)
  
    #Read the rain gage data from the mars database
  rainfall_gage <- dbGetQuery(marsDBCon, "SELECT * from data.viw_gage_rain_latestdates")  
  
  #Read the rain gage table from the mars database and attach it to the rainfall data
  gage <- dbGetQuery(marsDBCon, "SELECT * FROM admin.tbl_gage")
  rainfall_gage <- right_join(rainfall_gage, gage, by = "gage_uid") %>% 
    transmute(gage_uid, 
              maxtime = force_tz(coalesce(maxtime, ymd("1900-01-01")), "America/New_York")) 
  
  
```

```{r Gather Rain Gage Data from H&H, echo=FALSE, include = TRUE, eval = !kill}

  #Read the rain gage data from the H&H database
hhrainfall_gage <- dbGetQuery(centraldb, "select * from pwdrg.tblModelRain") %>% 
  transmute(gage_uid = GaugeNo, 
            dtime = DateTime, #Comes in as America/New York time zone
            rainfall_in = round(Rainfall, 4)) %>%
  filter(!(gage_uid %in% c(36, 37))) #We don't track these
  
  newgagedata <- hhrainfall_gage %>% 
    left_join(rainfall_gage, by = "gage_uid") %>% 
    group_by(gage_uid) %>%
    filter(dtime > maxtime) %>%
    ungroup %>%
    select(gage_uid, dtime, rainfall_in) %>%
    left_join(gage, by = "gage_uid") %>%
    select(gage_uid, dtime, rainfall_in) %>%
    arrange(gage_uid, dtime) %>%
    mutate(rainfall_in = round(rainfall_in, 4)) %>%
    mutate(key = paste(gage_uid, dtime, sep = "_"), dupe = duplicated(key)) %>%
    filter(!dupe) %>%
    select(-key, -dupe)
  
 summary_newgagedata <- group_by(newgagedata, gage_uid) %>%
    summarize(new_measurements = n(), 
              latest_date = max(dtime))
```

# Rain Gage Data
### There is `r ifelse(nrow(newgagedata) > 0, "", "not")` new rain gage data to import.

```{r Section R1: New Gage Data Output, echo = FALSE, include = TRUE, eval = all(nrow(newgagedata) > 0, !kill)}
    knitr::asis_output(paste("### New Rain Gage Data to add to `data.tbl_gage_rain`: ", nrow(newgagedata), "Records"))
  
  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = logCode,
                           milestone = 3,
                           exit_code = NA,
                           note = "Writing Gage Data")
  
  dbWriteTable(marsDBCon, RPostgres::Id(schema = "log", table = "tbl_script_rainfall"), logMessage, append = TRUE, row.names=FALSE)
  
  #Write the gages one by one
  #Prepare a table of outcomes.
  gage_outcomes <- data.frame(gage_uid = summary_newgagedata$gage_uid,
                              success = NA) #Success will be recorded on a per-gage basis
                                            #All gages will attempt to write, but any failure will set KILL
                                            #And halt the script after this chunk
  
  for(i in 1:nrow(gage_outcomes)){
    singlegage_rain <- filter(newgagedata, gage_uid == gage_outcomes$gage_uid[i]) %>%
      arrange(dtime) #Order it old to new
    
    tryCatch(
  
        expr = {
          print(paste("Writing Rain Gage", gage_outcomes$gage_uid[i]))
          dbWriteTable(marsDBCon, RPostgres::Id(schema = "data", table = "tbl_gage_rain"), singlegage_rain, append= TRUE, row.names = FALSE)
          gage_success <<- TRUE #Global assign because we are in a trycatch
          },
        error = function(e) {
          print(e$message)
          gage_success <<- FALSE
          kill <<- TRUE
        }
      )
    gage_outcomes$success[i] <- gage_success
    #Writing file counts
    if(gage_outcomes$success[i] == TRUE){ #If the write succeeded
      logMessage <- data.frame(date = as.Date(today()),
                           records = nrow(singlegage_rain),
                           type = paste("Records for Rain Gage", gage_outcomes$gage_uid[i]),
                           hash = logCode)
  
      dbWriteTable(marsDBCon, RPostgres::Id(schema = "log", table = "tbl_writes_rainfall"), logMessage, append = TRUE, row.names=FALSE)
    }
    
  }

  output_gageresults <- left_join(gage_outcomes, summary_newgagedata)
  kable(output_gageresults)

```

```{r Section 3 - Gathering radar data, include = FALSE}
  ###Log: Start
  logMessage <- data.frame(date = as.Date(today()), hash = logCode,
                           milestone = 6,
                           exit_code = NA,
                           note = "Gathering Radar Data")
  
  dbWriteTable(marsDBCon, RPostgres::Id(schema = "log", table = "tbl_script_rainfall"), logMessage, append = TRUE, row.names=FALSE)  

  
  #Assess raw files in our DB and H&H
  db_rawfiles <- dbGetQuery(marsDBCon, "select * from admin.tbl_radar_rawfile")
  hh_rawfiles <- list.files(radarFolder, pattern = "*\\.zip$") #List all the zip files in that folder

  #Which files don't we have
  new_rawfiles <- data.frame(filepath = paste(radarFolder, 
                                              hh_rawfiles[!(hh_rawfiles %in% db_rawfiles$filepath)], 
                                              sep = "/"), #Compose the full path to extract the files
                             stringsAsFactors = FALSE) %>%
    mutate(yearmon = str_replace(filepath, ".*(\\d{4})-(\\d{2}).*", "\\1\\2"), #Extract the YYYYMM yearmonth from the filename
              #Regex notes:
              #() creates a capture group, referred to as \\1 and \\2 (capture group 1 and 2) in the replacement string
                #\\d means "any digit 0-9", {4} and {2} means "4 (or 2) of the preceeding character"
                #- is a literal hyphen, and is outside the capture groups
                #so the capture groups means DDDD and DD, where D is any digit 0-9
              #The . means "any character", and the * means "any number of the preceeding character"
                #So the .* before the first capture group means everything before the YYYY
                #And the .* after the second capture group means everything after the MM
              #The replacement string is just the reference to both capture groups
                #So everything not in the capture group is replaced with nothing
                #In practice, this means /path/to/foo_2025-04_bar.zip is replaced by 202504
                #We want this because the CSV containing the data in 2025-04.zip is named 202504.csv
              #For more information, see https://regexr.com
          datafile = paste0(yearmon, ".csv")) #Compose that CSV's file name

```

# Radar Rainfall Data
### There are `r nrow(new_rawfiles)` months worth of radar rainfall data to import.
### Since this is a test, we are only importing 1
```{r Section 4 - Reading radar data, include = FALSE, eval = all(nrow(new_rawfiles) > 0, !kill)}

  #Create the data frame that will iteratively hold all the new data
  newradardata <- data.frame(dtime = NULL, radar_uid = NULL, rainfall_in = NULL)

  #Only import grid cells in Philadelphia county
  phillycells <- dbGetQuery(marsDBCon, "select radar_uid from admin.tbl_radar")

  #Unzip the files
  dir.create(unzipFolder, showWarnings = FALSE)
  #for(i in 1:nrow(new_rawfiles)){
  for(i in 10){ #DEBUG: only process the tenth file (has a dst fallback, these introduce parsing corner cases to test)
    #Unzip the file
    file.copy(from = new_rawfiles$filepath[i], to = unzipFolder, overwrite = TRUE)
    unzip(new_rawfiles$filepath[i], exdir = unzipFolder, files = new_rawfiles$datafile[i]) #extract only the CSV we want
    
    #Read the file
    currentfile <- paste(unzipFolder, new_rawfiles$datafile[i], sep = "/")
    currentdata <- read_csv(currentfile, 
                            col_names = c("dtime_raw", "tzone", "radar_uid", "rainfall_in"), #CSV file has no column headers
                            col_types = c("c", "c", "i", "d")) #character, character, integer, double (see ?read_csv col_types argument)
                                                               #We need to read the datetime in as a string to prevent R from mishandling time zones
    
    #The tzone member of this data frame contains one of two values - "EST" or "EDT"
      #The dtime member is the raw local clock time and corrects for daylight savings 
        #ie, it skips 2:00 AM at the spring-forwards and repeats 1:00 AM at the fall-back
    
    #When we parse dtime_raw with ymd_hm, we will run into a limitation of lubridate's datetime parser
    #The parser can only apply a single time zone value to the entire vector, 
      #and will always return the same UTC offset when given the same input string
    
    #This is a problem when daylight savings time falls back. 
      #As stated above, the clock values in the 1:00 AM hour will be repeated when this happens.
      #In order to properly keep the time series chronologically ordered, we need different UTC offsets for the repeated 1:00 AM hour
        #eg 1:00:00-04, 1:15:00-04, 1:30:00-04, 1:45:00-04, 1:00:00-05, 1:15:00-05, etc
        #If we don't have this, the dtimes will sort incorrectly (00:45:00, 1:00:00, 1:00:00, 1:15:00, etc)
        #It will also violate the uniqueness constraint in our SQL tables, where only one combination of each dtime and radar_uid is permissable
      #Lubridate will not correctly parse datetime data from text in this way.
        #eg both 1:00:00 values will be given a UTC offset of -04
        #it will not give a -05 offset until 03:00:00, when America/New_York always has an offset of -05
    
    #In order to correct this, we need to use the force_tzs function to coerce the offsets of the repeated times into their correct form
      #This bug took me 6 hours to fix, and I tried everything from parsing the data frame in two separate batches (needlessly complex)
      #To manually composing a -05/-04 UTC offset string to feed to ymd_hm (creates parse errors)
      #As far as I know, this is the most elegant solution that exists with our current tools.
    
    finalCurrentData <- currentdata %>%
      filter(radar_uid %in% phillycells$radar_uid) %>% #Only the grid cells in Philadelphia county
             #rainfall_in > 0)
                #Normally, we would strip the 0 values so we don't store gigabytes of extra data
                #For now, we will not strip them, so it gives us a chance to correctly parse the DST fallback
      mutate(dtime_intermediate = ymd_hm(dtime_raw, tz = "America/New_York"),
             dtime = force_tzs(dtime_intermediate, tzones = tzone)) %>% #Correct for the above time zone offset error
      select(dtime, radar_uid, rainfall_in)

      tryCatch(
  
        expr = {
          print(paste("Writing Radar Data File", new_rawfiles$datafile[i]))
          dbWriteTable(marsDBCon, RPostgres::Id(schema = "data", table = "tbl_radar_rain"), finalCurrentData, append= TRUE, row.names = FALSE)
          radar_success <<- TRUE #Global assign because we are in a trycatch
          },
        error = function(e) {
          print(e$message)
          radar_success <<- FALSE
          kill <<- TRUE
        }
      )
  }
  
```

### Radar Rainfall file `r new_rawfiles$datafile[i]` has `r ifelse(radar_success, print("successfully"), print("NOT successfully"))` been imported
### It contained `r nrow(finalCurrentData)` data points
