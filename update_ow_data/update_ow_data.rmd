---
title: "Worker Script Report: Update OW Data"
author:
- Taylor Heffernan
- Updating ow_leveldata
date: "`r lubridate::now()`" 
output: html_document
---

```{r setup, include=FALSE}

#Dplyr stuff
library(magrittr)
library(tidyverse)
library(lubridate)

#Database Stuff
library(RODBC)
library(odbc)

#Other stuff
library(knitr)
options(stringsAsFactors=FALSE)

options(stringsAsFactors=FALSE)

errorCodes <- data.frame(code = 0:5,
  message = c("Execution successful.",
              "Could not connect to Postgres DB. Is Postgres down?",
              NA, #Error from TryCatch will be used
              NA, #Error from TryCatch will be used
              NA,  #Error from TryCatch will be used
              NA  #Error from TryCatch will be used
              ), stringsAsFactors=FALSE)

keepRunningMain = TRUE
keepRunningCWL = TRUE
keepRunningGW = TRUE
success = FALSE
errorCode = 0


```

```{r Section 0 - Preamble and database connections, include=FALSE, eval = keepRunningCWL}
###Section 0.1: Check parameter validity

###Section 0.2: Connect to the database
 	#Connect using the DSN.
	marsDBCon <- dbConnect(odbc::odbc(), "mars_data14")

  #################################
  ####Error check - Did we connect?
  #################################
  if(!odbc::dbIsValid(marsDBCon))
  {
    keepRunning = FALSE
    errorCode = 1
  }
	
```

```{r Section 1A - Gathering OW data, include = FALSE, eval = keepRunningMain}

  #Read the latest date from each observation well from the mars database
  ow_latestdates <- dbGetQuery(marsDBCon, "SELECT * FROM data.viw_owdata_latestdates") %>%
    mutate(dtime_est = force_tz(dtime_est, tz = "EST")) #Adjust time zone without moving timestamp
  
  #Read the accessdb table from the mars database and attach it to the date data
  accessdb <- dbGetQuery(marsDBCon, "SELECT filepath, ow_uid, datatable, sumptable FROM admin.tbl_accessdb")
  accessdb_latestdates <- left_join(ow_latestdates, accessdb, by = "ow_uid") %>% 
    filter(!is.na(filepath), !is.na(datatable))
  
  #Read the data from each Access DB's data table, 
  newdata <- data.frame(dtime_est = NULL, ow_uid = NULL, level_ft = NULL) #data frame to incrementally append to

  for(i in 1:nrow(accessdb_latestdates)){
    #Debug statement. Uncomment if running interactively.
    print(paste("Accessing", accessdb_latestdates$filepath[i]))
    
    tryCatch(
      expr = {
        accessdbCon <- odbcConnectAccess2007(accessdb_latestdates$filepath[i])
        accessdb_latestdates$dtime_est[i][is.na(accessdb_latestdates$dtime_est[i])] <- mdy('2/20/2001', tz = "EST")
        accessdb_query <- paste0("select * from [", accessdb_latestdates$datatable[i], "] where [Standard Dtime] > #",accessdb_latestdates$dtime_est[i], "# ")
        #print(accessdb_query)
    
        accessdb_newdata <- sqlQuery(accessdbCon, accessdb_query, as.is = TRUE) %>%
           select(dtime_est = 1, level_ft = ncol(.)) %>% #dtime is the first column, level is the last
           mutate(dtime_est = ymd_hms(dtime_est, tz = "EST"), level_ft = as.numeric(level_ft)) %>% #Data comes in as plain text from RODBC
           filter(dtime_est > accessdb_latestdates$dtime_est[i]) %>% #We still need to filter by > the latest date because Access will treat values with fractional seconds as > values without fractional seconds. When R recieves them, though, we get them without the fractional seconds, so from our perspective, we have a value that is = the latest date. This is very silly.
           arrange(dtime_est) %>% #Order by ascending datetime in case it's out of order in the DB
           mutate(ow_uid = accessdb_latestdates$ow_uid[i]) %>% #Attach OW UID to the data
           mutate(key = paste(ow_uid, dtime_est, sep = "_"), 
                  dupe = duplicated(key)) %>% #Sometimes there are duplicates in the Access DBs
           filter(dupe == FALSE) %>% #Remove the dupe rows
           select(-key, -dupe) #Remove the key columns
           
        newdata <- bind_rows(newdata, accessdb_newdata)
        odbcClose(accessdbCon)
      },
      error = function(e){
        keepRunningMain <<- FALSE
        errorCode <<- 2
        errorCodes$message[errorCode+1] <<- e$message #Error object is a list
      }
    )
  }
  
  #Some nulls may exist so we purge them
  #But only if we are proceeding with execution
  if(keepRunningMain){
    newdata %<>% filter(complete.cases(newdata))
    newdata$dtime_est <- newdata$dtime_est %>% 
      round_date(unit = "minute") %>%
      as.character  
  }
  

  #Pull OW table for use in the report table
  ow <- dbGetQuery(marsDBCon, "select * from fieldwork.tbl_ow")
  
  #################################
  ####Error check - Any new data?
  #################################
  if(nrow(newdata) == 0)
  {
    # This is possible if all the new files are empty
    keepRunningCWL = FALSE
    display_newdata <- NULL
  } else{
    display_newdata <- newdata %>% 
      group_by(ow_uid) %>% 
      summarize(data_points = n(), first_est = first(dtime_est), last_est = last(dtime_est)) %>%
      left_join(ow, by = "ow_uid") %>%
      select(smp_id, ow_suffix, ow_uid, first_est, last_est, data_points)
    #count unique wells with new data
  }

```


```{r Section 1B - Writing to the tbl_ow_leveldata_raw table, include = FALSE, eval = all(keepRunningMain, keepRunningCWL, nrow(display_newdata) > 0)}	
  knitr::asis_output(paste0("###The ", nrow(display_newdata), " updated wells contain ", nrow(newdata), " new CWL data points"))

  kable(display_newdata)

  #Create a data frame of file-by-file writing results
  if(nrow(newdata) > 0){
    owdata_results <- newdata %>% 
      group_by(ow_uid) %>% 
      summarize(outcome = NA, data_points = n()) %>% 
      left_join(ow, by = "ow_uid") %>% 
      transmute(smp_id, ow_suffix, ow_uid, 
                data_points, 
                outcome)
  } else {
    owdata_results <- data.frame(NULL)
  }


  #Write each well's worth of data to the database one at a time
  for(i in 1:nrow(owdata_results)){
    if(nrow(owdata_results) == 0){break} #If there are no new data sources, don't do anything
    
    newdata_currentfile <- filter(newdata, ow_uid == newdata_results$ow_uid[i])

    if(nrow(newdata_currentfile) > 0){
      tryCatch({owdata_results$outcome[i] <- dbWriteTable(marsDBCon, 
          DBI::SQL("data.tbl_ow_leveldata_raw"), 
          newdata_currentfile, 
          append= TRUE, 
          row.names = FALSE)
        }, # append the data
        error = function(e){
          keepRunningMain <<- FALSE
          errorCode <<- 3
          errorCodes$message[errorCode+1] <<- e$message #Error object is a list
          success <<- TRUE
        }
      )
    }
    
  }
```


```{r Section 2A - Gathering GW data, include = FALSE, eval = keepRunningMain}

  #Read the latest date from each observation well from the mars database
  gw_latestdates <- dbGetQuery(marsDBCon, "SELECT * FROM data.viw_gwdata_latestdates") %>%
    mutate(dtime_est = force_tz(dtime_est, tz = "EST")) #Adjust time zone without moving timestamp
  
  #Read the accessdb table from the mars database and attach it to the date data
  accessdb <- dbGetQuery(marsDBCon, "SELECT filepath, ow_uid, datatable, sumptable FROM admin.tbl_accessdb")
  accessdb_latestdates <- left_join(gw_latestdates, accessdb, by = "ow_uid") %>% filter(!is.na(filepath), !is.na(datatable))
  
  #Read the data from each Access DB's data table, 
  newdata <- data.frame(dtime_est = NULL, ow_uid = NULL, depth_ft = NULL) #data frame to incrementally append to

  for(i in 1:nrow(accessdb_latestdates)){
  #Debug statement. Uncomment if running interactively.
  print(paste("Accessing", basename(accessdb_latestdates$filepath[i])))

  #We need RODBC to connect to the DBs because odbc::odbc throws a "DSN too long" error. I would like to fix this sometime
  tryCatch(
    expr = {
      accessdbCon <- RODBC::odbcConnectAccess2007(accessdb_latestdates$filepath[i])
      accessdb_latestdates$dtime_est[i][is.na(accessdb_latestdates$dtime_est[i])] <- mdy('2/20/2001', tz = "EST") #replace NAs with an early date
      accessdb_query <- paste0("select * from [", accessdb_latestdates$datatable[i], "] where [Standard Dtime] > #",accessdb_latestdates$dtime_est[i], "# ") #query new rows
      #print(accessdb_query)


      accessdb_newdata <- sqlQuery(accessdbCon, accessdb_query, as.is = TRUE) %>% 
      select(dtime_est = 1, depth_ft = ncol(.)) %>% #dtime is the first column, level is the last
      mutate(dtime_est = ymd_hms(dtime_est), depth_ft = as.numeric(depth_ft)) %>% #Data comes in as plain text from RODBC
      filter(dtime_est > accessdb_latestdates$dtime_est[i]) %>% #Only take the new data
      arrange(dtime_est) %>% #Order by ascending datetime in case it's out of order in the DB
      mutate(ow_uid = accessdb_latestdates$ow_uid[i]) %>% #Attach OW UID to the data
      mutate(key = paste(ow_uid, dtime_est, sep = "_"), 
              dupe = duplicated(key)) %>% #Sometimes there are duplicates in the Access DBs
       filter(dupe == FALSE) %>% #Remove the dupe rows
       select(-key, -dupe) #Remove the key columns
      
      newdata <- bind_rows(newdata, accessdb_newdata)
      odbcClose(accessdbCon)
    },
    error = function(e){
      keepRunningMain <<- FALSE
      errorCode <<- 4
      errorCodes$message[errorCode+1] <<- e$message #Error object is a list
    }
  )
}
  
  
  #Some nulls may exist so we purge them
  newdata %<>% filter(complete.cases(newdata))
  newdata$dtime_est <- newdata$dtime_est %>% 
    round_date(unit = "minute") %>%
    as.character
  
  #################################
  ####Error check - Any new data?
  #################################
  if(nrow(newdata) == 0)
  {
    # This is possible if all the new files are empty
    keepRunningGW = FALSE
    display_newdata <- NULL
  } else{
    display_newdata <- newdata %>% 
      group_by(ow_uid) %>% 
      summarize(data_points = n(), first_est = first(dtime_est), last_est = last(dtime_est)) %>%
      left_join(ow, by = "ow_uid") %>%
      select(smp_id, ow_suffix, ow_uid, first_est, last_est, data_points)
    #count unique wells with new data
  }

```

```{r Section 2B - Writing to the tbl_gw_depthdata table, include = FALSE, eval = all(keepRunningMain, keepRunningGW, nrow(display_newdata) > 0)}	
  knitr::asis_output(paste0("###The ", nrow(display_newdata), " updated wells contain ", nrow(newdata), " new CWL data points"))

  kable(display_newdata)

  #Create a data frame of file-by-file writing results
  if(nrow(newdata) > 0){
    gwdata_results <- newdata %>% 
      group_by(ow_uid) %>% 
      summarize(outcome = NA, data_points = n()) %>% 
      left_join(ow, by = "ow_uid") %>% 
      transmute(smp_id, ow_suffix, ow_uid, 
                data_points, 
                outcome)
  } else {
    gwdata_results <- data.frame(NULL)
  }


  #Write each well's worth of data to the database one at a time
  for(i in 1:nrow(gwdata_results)){
    if(nrow(gwdata_results) == 0){break} #If there are no new data sources, don't do anything
    
    newdata_currentfile <- filter(newdata, ow_uid == newdata_results$ow_uid[i])

    if(nrow(newdata_currentfile) > 0){
      tryCatch({gwdata_results$outcome[i] <- dbWriteTable(marsDBCon, 
          DBI::SQL("data.tbl_gw_depthdata_raw"), 
          newdata_currentfile, 
          append= TRUE, 
          row.names = FALSE)
        }, # append the data
        error = function(e){
          keepRunning <<- FALSE
          errorCode <<- 5
          errorCodes$message[errorCode+1] <<- e$message #Error object is a list
          success <<- TRUE
        }
      )
    }
    
  }
```

# Script Results: `r ifelse(keepRunningMain, "SUCCESS", "FAILURE")`
## Exit Code: `r errorCode`
## Exit Message: `r errorCodes$message[errorCode+1]`

```{r Section 3 - Close DB connections and render this file, include = FALSE}
	#Close database connections
	dbDisconnect(marsDBCon)
```
