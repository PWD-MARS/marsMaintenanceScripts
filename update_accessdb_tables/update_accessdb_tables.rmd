---
title: "MARS Maintenance Script: Update AccessDB Tables"
author:
- Taylor Heffernan
- Updating accessdb and ow_sumpdepth
date: "`r lubridate::now()`"
output: html_document
params:
  database: "mars_data14"

---

```{r setup, include=FALSE}

#Dplyr stuff
library(magrittr)
library(tidyverse)

#Database Stuff
library(odbc)
library(RODBC)

#Other stuff
library(knitr)

options(stringsAsFactors=FALSE)

errorCodes <- data.frame(code = 0:9,
  message = c("Execution successful.",
              "Could not connect to Postgres DB. Is Postgres down?",
              "No Access DBs found when crawling public/private site folders. Are we connected to Active Directory?",
              "Access DBs found without a corresponding fieldwork.tbl_ow entry. Was a Location created in the app?",
              "Existing DBs not found in the filesystem. Have any been moved or renamed?",
              5,
              6,
              7,
              8,
              9), stringsAsFactors=FALSE)

keepRunning = TRUE
errorCode = 0

```

```{r Section 0A - Preamble and database connections, include=FALSE}
###Section 0.1: Check parameter validity

###Section 0.2: Connect to the database
 	#Connect to MARS database using ODBC channel
	marsDBCon <- dbConnect(odbc::odbc(), params$database)

  #################################
  ####Error check - Did we connect?
  #################################
  if(!odbc::dbIsValid(marsDBCon))
  {
    keepRunning = FALSE
    errorCode = 1
  }


```

```{r Section 0B - Preamble, include = FALSE, eval = keepRunning}
	#Refresh materialized view so it has the newest cache of SMP IDs
	#If we don't do this, new IDs won't be found, and we will get an insertion error.
	dbGetQuery(marsDBCon, "REFRESH MATERIALIZED VIEW external.mat_assets WITH DATA;")

###Section 0.3: Other basic parameters
	publicsitefolder <- "//pwdoows/oows/Watershed Sciences/GSI Monitoring/02 GSI Monitoring Sites"
	privatesitefolder <- "//pwdoows/oows/Watershed Sciences/GSI Monitoring/02 GSI Monitoring Sites/z_Private Monitoring Sites"

###Section 0.4: Parser functions
	#Public SMP parser function
	#Extract public SMP IDs (X-Y-Z) from strings (like a file path)
	#Returns X-Y-Z if it finds it, NA if it doesn't. If it finds multiple X-Y-Zs in one string, it returns the first one.
	parsePublicSMPs <- function(strings){
  	finalvector <- rep(NA, length(strings))
  	matchindex <- which(grepl("\\d+-\\d+-\\d+", strings))
  	finalvector[matchindex] <- regexpr("\\d+-\\d+-\\d+", strings) %>% {regmatches(strings, .)}
  	return(finalvector)
	}
	
	#Public OW parser function
 	#Extract monitoring device IDs (OW1, GW4, etc) at public SMPs from strings. String must be in the form X-Y-Z_ABC.
	#Returns AAA extracted from X-Y-Z_AAA if it finds it. Returns NA if it doesn't. 
	#If it finds X-Y-Z_ABC followed by X-Y-Z_DEF within the same string, it returns ABC.
	#If it finds X-Y-Z_ABCD in the string, it returns ABC.
	parsePublicOWs <- function(strings){
		finalvector <- rep(NA, length(strings))
		matchindex <- which(grepl("\\d+-\\d+-\\d+.+?([A-Za-z]{2}\\d{1})", strings, perl=TRUE))
		finalvector[matchindex] <- gsub("^.*\\d+-\\d+-\\d+.+?([A-Za-z]{2}\\d{1}).*$", "\\1", strings, perl=TRUE)[matchindex]
		finalvector %<>% toupper
		return(finalvector)
  }

	#Private SMP parser function
	#Extract private SMP IDs (XXXXX) from strings (like a file path)
	#Returns XXXXX if it finds it, NA if it doesn't. If it finds multiple XXXXXs in one string, it returns the first one.
	parsePrivateSMPs <- function(strings){
  	finalvector <- rep(NA, length(strings))
  	matchindex <- which(grepl("\\d{5}", strings))
  	finalvector[matchindex] <- regexpr("\\d{5}", strings) %>% {regmatches(strings, .)}
  	return(finalvector)
	}
	
	#Private OW parser function
 	#Extract monitoring device IDs (OW1, GW4, etc) at private SMPs from strings. String must be in the form XXXXX_ABC.
	#Returns AAA extracted from XXXXX_AAA if it finds it. Returns NA if it doesn't. 
	#If it finds XXXXX_ABC followed by XXXXX_DEF within the same string, it returns ABC.
	#If it finds XXXXX_ABCD in the string, it returns ABC.
	parsePrivateOWs <- function(strings){
		finalvector <- rep(NA, length(strings))
		matchindex <- which(grepl("\\d{5}.+?([A-Za-z]{2}\\d{1})", strings, perl=TRUE))
		finalvector[matchindex] <- gsub("^.*\\d{5}.+?([A-Za-z]{2}\\d{1}).*$", "\\1", strings, perl=TRUE)[matchindex]
		finalvector %<>% toupper
		return(finalvector)
	}
  
```
  
This script is attempting to update the `admin.tbl_accessdb` and `fieldwork.tbl_ow_sumpdepth_intermediate`tables in the `r params$database` database. It crawls the GSI Monitoring Sites folder, and does the following:  
  
 1. Update the `admin.tbl_accessdb` table's set of information for GSI site Access DBs (`tbl_accessdb.filepath`, `tbl_accessdb.ow_uid`)  
  * Look for all Access DBs in the roots of the various site folders (file paths end with .mdb or .accdb)
  * Verify that all DB paths contained in `tbl_accessdb.filepath` can be found
  * For newly created Access DBs, parse their filepath and look in `fieldwork.tbl_ow` for matching `tbl_ow.smp_id` and `tbl_ow.ow_suffix`
  * Look for deleted/moved DBs, whose file paths can no longer be found
  
 2. Update the `admin.tbl_accessdb` table's set of canonical GSI table names (`tbl_accessdb.datatable`, `tbl_accessdb.sumptable`)
  * Loop through Access DBs (`tbl_accessdb.filepath`), checking each for canonical data tables and stage-storage tables.
  * Create data frames of additions to the set of canonical table names, and existing table names that can no longer be found
  
 3. Update the sump depths in the `fieldwork.tbl_ow_sumpdepth_intermediate` table  
  
---  
  
```{r Section 1 - Gathering data for the accessdb table, include = FALSE, eval = keepRunning}
  ###Section 1.1 Scan site folders
    #Find public site folders within 02 GSI Monitoring Sites
    #Site folders will end with an underscore and a number (eg _123)
    publicsitefolders <- grep("_\\d+$", list.dirs(publicsitefolder, recursive = FALSE), value = TRUE)
    
    #Find private site folders within 02 GSI Monitoring Sites/z_Private Monitoring Sites
    #Site folders will end with an underscore, three 4-character blocks, and a 2-character block separated by hyphens
    #(eg _FY16-WAKE-4282-01)
    privatesitefolders <- grep("_\\w{4}-\\w{4}-\\w{4}-\\w{2}$", list.dirs(privatesitefolder, recursive = FALSE), value = TRUE)
    
    #Look in each folder for an Access DB
    publicaccessdbs <- list.files(publicsitefolders, "\\.accdb$|\\.mdb$", recursive=FALSE, full.names=TRUE)
    privateaccessdbs <- list.files(privatesitefolders, "\\.accdb$|\\.mdb$", recursive=FALSE, full.names=TRUE)
    
    ##############################################
    ####Error check - did we find access DB files?
    ##############################################
    if(length(publicaccessdbs) == 0 | length(privateaccessdbs) == 0)
    {
      keepRunning = FALSE
      errorCode = 2
    }
    
    #Fetch current version of the AccessDB table
    accessdbtable_server <- dbGetQuery(marsDBCon, "SELECT * FROM admin.tbl_accessdb")
    
```

```{r Section 1A - New Databases, include = FALSE, eval = keepRunning}
    
  ###Section 1.2 Parse new DB names, SMP IDs, and OW suffixes
    #Exclude DBs already in the table
    publicaccessdbs_new <- publicaccessdbs[!(publicaccessdbs %in% accessdbtable_server$filepath)]
    privateaccessdbs_new <- privateaccessdbs[!(privateaccessdbs %in% accessdbtable_server$filepath)]
    
    #Parse the filepaths of the new DBs for SMP IDs and OW suffixes
    publicaccessdbs_df <- data.frame(filepath_server = publicaccessdbs_new) %>% mutate(smp_id = parsePublicSMPs(filepath_server), ow_suffix = parsePublicOWs(filepath_server))
    privateaccessdbs_df <- data.frame(filepath_server = privateaccessdbs_new) %>% mutate(smp_id = parsePrivateSMPs(filepath_server), ow_suffix = parsePrivateOWs(filepath_server))
    
    #Connect the public and private sites
    allnewaccessdbs_df <- bind_rows(publicaccessdbs_df, privateaccessdbs_df)
  
  ###Section 1.3 Connect ow_uids to SMP IDs and OW suffixes
    #Fetch current version of the OW table
    ow <- dbGetQuery(marsDBCon, "SELECT * FROM fieldwork.tbl_ow")
    
    #Join our new AccessDB file paths to the current OW table (to attach ow_uids)
    allnewaccessdbs_ow <- left_join(allnewaccessdbs_df, ow, by = c("smp_id", "ow_suffix"))
    
  ###Section 1.4 Reconcile the new Access DBs with the existing defined OWs
    #1.4.1 New Access DBs that have matching defined OWs need can be added to the `admin.accessdb` table
    output_newAccessDBs <- filter(allnewaccessdbs_ow, !is.na(ow_uid)) %>% mutate(filepath = filepath_server)


```    
  
```{r Section 1B - Incomplete entries, include = FALSE, eval = keepRunning}
    #1.4.2 New Access DBs that don't have defined OWs need OWs defined for them
    #All this script can do is report on these
    accessdbswithoutow <- filter(allnewaccessdbs_ow, is.na(ow_uid)) %>% mutate(filepath = filepath_server)

    ##############################################
    ####Error check - did we find orphaned DB files?
    ##############################################
    if(length(accessdbswithoutow) > 0)
    {
      keepRunning = FALSE
      errorCode = 3
    }

    #Which known DBs weren't found? (Maybe deleted or moved)
    existingdbs_notfound <- filter(accessdbtable_server, !(filepath %in% c(publicaccessdbs, privateaccessdbs)))
    
    ##############################################
    ####Error check - did we fail to find any DBs?
    ##############################################
    if(length(existingdbs_notfound) > 0)
    {
      keepRunning = FALSE
      errorCode = 4
    }

    
```

```{r Section R1: New Databases Output, echo = FALSE, eval = keepRunning}
    knitr::asis_output(paste("### New Access DBs to add to `admin.tbl_accessdb`: ",   nrow(output_newAccessDBs), "  "))

    if(nrow(output_newAccessDBs) > 0){
      newdbs_display <- output_newAccessDBs %>% transmute(smp_id, ow_suffix, ow_uid, file = basename(filepath))
      
      kable(newdbs_display)
    }

    ###Trycatch to write and capture error

```
  
```{r Section 2 - Checking the Access DBs for canonical table names, include = FALSE, eval = keepRunning}

  ###Pull Access table again

  #Compose a data frame to use to check for tables in the Access databases
  #We need to verify that the tables we think are there still exist, and check for new ones
  #If there's a value in accessdb.datatable or accessdb.sumptable, we will use those
  #If there isn't, we will compose a guess as to what they might be based on ow.smp_id and ow.ow_suffix
  #We will also create a variable for the result of our guesses
  accessdb_tableguesses <- left_join(accessdbtable_server, ow, by = "ow_uid") %>%
      mutate(datatable_guess = ifelse(is.na(datatable), paste(smp_id, ow_suffix, "CWL_Monitoring", sep = "_"), datatable),
             sumptable_guess = ifelse(is.na(sumptable), paste(smp_id, ow_suffix, "Stage_Storage_final", sep = "_"), sumptable),
             datatable_guessresult = NA,
             sumptable_guessresult = NA)

  for(i in 1:nrow(accessdb_tableguesses)){
    #Debug statement. Uncomment if running interactively.
    # print(paste("Accessing", basename(accessdb_tableguesses$filepath[i])))

    #We need RODBC to connect to the DBs because odbc::odbc throws a "DSN too long" error. I would like to fix this sometime
    accessdbCon <- RODBC::odbcConnectAccess2007(accessdb_tableguesses$filepath[i])

    #List the tables in each database and check to see if we can find the guessed table name in there
    dbtables <- RODBC::sqlTables(accessdbCon)
    accessdb_tableguesses$datatable_guessresult[i] <- dbtables %>% {accessdb_tableguesses$datatable_guess[i] %in% .$TABLE_NAME}
    accessdb_tableguesses$sumptable_guessresult[i] <- dbtables %>% {accessdb_tableguesses$sumptable_guess[i] %in% .$TABLE_NAME}

    RODBC::odbcClose(accessdbCon)
    
    #####If there's a crash, catch it here.####
    
  }

  ####New block for this####

  #Create the data frames of results to print/summarize
  #Access DBs where our current stored table names are both correct
    #Either we found what we expected to find, or we didn't find anything and expected to find nothing
    #IE: Our guess equalled what we thought was there, or expected our guess to be wrong because we didn't think there was a table
    #We do it this way so we can more easily detect if a DB we thought had no table had one created since we last checked
    #If we just checked for what we thought was there, we'd still have to check again to see if any new tables got created
  accessdb_nochange <- filter(accessdb_tableguesses,
      (sumptable_guessresult == TRUE & sumptable_guess == sumptable) | (sumptable_guessresult == FALSE & is.na(sumptable)),
      (datatable_guessresult == TRUE & datatable_guess == datatable) | (datatable_guessresult == FALSE & is.na(datatable)))

  #Access DBs where we we found tables where we thought there were none
    #IE: We had no table name stored, and we found one with our guesses
    accessdb_foundnewtables <- filter(accessdb_tableguesses,
      (sumptable_guessresult == TRUE & is.na(sumptable)) | (datatable_guessresult == TRUE & is.na(datatable)))


  #Access DBs where we didn't find tables we thought were there
    accessdb_missedsomething <- filter(accessdb_tableguesses,
      (sumptable_guessresult == FALSE & !is.na(sumptable)) | (datatable_guessresult == FALSE & !is.na(datatable)))
    
    ####Error on this####
    
  #Access DBs with no canonical tables
    #Only checking for data table, because without a data table, a sump table is meaningless
    accessdb_nocanonical <- filter(accessdb_tableguesses, datatable_guessresult == FALSE, is.na(datatable))

    ####Error on this####
    
```
  


```{r Section 3 - Gather data for new/updated sump depths, include=FALSE, eval = keepRunning}
  #Filter AccessDBs to DBs with a sumptable, connect to each DB, check each stage storage curve for a sump depth (>0, 0)

  #Grab known sump depths from the postgres database and compare them to the stae of the various accessdbs
  ow_sumpdepth <- dbGetQuery(marsDBCon, "SELECT * FROM fieldwork.tbl_ow_sumpdepth_intermediate")
  
  #Attach sump depths to OWs and Access DBs
  accessdbs_sumpdepths <- left_join(accessdbtable_server, ow, by = "ow_uid") %>% 
    left_join(ow_sumpdepth, by = "ow_uid") %>% 
    filter(!is.na(sumptable)) %>%
    select(ow_uid, filepath, sumptable, sumpdepth_ft, smp_id, ow_suffix)
  
  #Check sump depths of systems with sumptables to see if they've changed
  accessdbs_sumpdepths$newsumpdepth_ft <- NA

  for(i in 1:nrow(accessdbs_sumpdepths)){
    #Connect to the DB to find the sump depth contained within it
    #We need RODBC to connect to the DBs because odbc::odbc throws a "DSN too long" error. I would like to fix this sometime
    con <- RODBC::odbcConnectAccess2007(accessdbs_sumpdepths$filepath[i])
  
    ###Catch a connection failure
    
    #Grab the stage-storage curve
    ssc <- RODBC::sqlFetch(con, accessdbs_sumpdepths$sumptable[i])
    colnames(ssc) <- c("level_in", "vol_ft3")
    
    #Find the sump depth within the stage storage curve
    #it will have level > 0 and volume = 0
    accessdbs_sumpdepths$newsumpdepth_ft[i] <- filter(ssc, vol_ft3 == 0) %>% 
      filter(level_in == max(level_in)) %>% 
      slice(1) %>%
      transmute(sumpdepth_ft = level_in / 12) %>% 
      pull(sumpdepth_ft) %>%
      round(4)

    RODBC::odbcClose(con)
  }
  
  #Have any existing measured sump depths changed?
  accessdbs_depthchanged <- filter(accessdbs_sumpdepths, !is.na(sumpdepth_ft), sumpdepth_ft != newsumpdepth_ft)
  
  #Did any sites get new sump depth measurements where there were none before?
  accessdbs_newmeasurement <- filter(accessdbs_sumpdepths, is.na(sumpdepth_ft), !is.na(newsumpdepth_ft))
  
  ####Write these in a new block####

    
```
  

```{r Section 4 - Close DB connections and render this file, include = FALSE}
	#Close database connections
	dbDisconnect(marsDBCon)